{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instagram_engagement.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJZ0c-Lj3AkV"
      },
      "source": [
        "## Results\n",
        "We found that the captions are very influential on a user's engagement with a post. They carry more weight than the topics depicted within the image. Zara will be able to increase user response to posts by focusing on creating engaging captions.\n",
        "\n",
        "The images yielding the greatest engagement featured models walking outside, wearing coats and dresses. Images that featured close ups of faces, full body shots of models sitting down wearing nice shoes, and models showcasing their bags were also significant. \n",
        "\n",
        "## Our process:\n",
        "1. Scraping Instagram: Extracting image URLs, captions, number of likes, and number of comments from most recent 700 posts on the Zara instagram account\n",
        "2. Obtaining Image Labels From Google Vision Cloud: Accessing the Google Vision API to detect and classify photo labels for each image in our dataset\n",
        "3. Measuring Engagement: Created a metric for engagement using a weighted sum of the number of likes and number of comments per post. We used min-max scaling to normalize these variables and assigned a weight of 0.4 to the number of likes and 0.6 to the number of comments. Comments were assigned a greater weight as they indicate the user engaged more actively with the post. \n",
        "\n",
        "  A binary engagement score was assigned to each post with a value of 1 if the engagement score is above the median engagement score and a value of 0 if below. This allows our metric for engagement to be relative to the posts we scraped. \n",
        "\n",
        "4. Predicting Engagement: Used three models to predict engagement using TF-IDF scores. TF-IDF scores calculate the frequency with which a word was used within one body of text relative to all the text data one has. It is a helpful tool to find key, relevant words within text documents. Using TF-IDF in this context helps us identify which key labels or words within a caption clearly distinguish the post and contribute to the user's engagement with the post. \n",
        "\n",
        "  ##### 1. Our first model predicted engagement using just image labels. \n",
        "  ##### 2. Our second model predicted engagement using just captions. \n",
        "  ##### 3. Our third model predicted engagement using both image labels and captions.\n",
        "\n",
        "5. Topic modeling (LDA) on the image labels:\n",
        "  \n",
        "  LDA topic modeling identifies the hidden semantic structure in our images. It's a probabilistic, unsupervised approach that clusters similar documents dependent upon the topics they share. These topics are identified recursively through finding which topics yield the highest probability for being generated from the labels within a given image.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM1zk3eZnWV8"
      },
      "source": [
        "## Scraping Instagram\n",
        "\n",
        "### Extracting image URLs, captions, number of likes, and number of comments from most recent 700 posts on the Zara instagram account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD0oH4eEe4TB"
      },
      "source": [
        "# Imports and Installs\n",
        "#!pip install instaloader\n",
        "import instaloader\n",
        "import pandas as pd \n",
        "import time\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLKPWBhjjXjz"
      },
      "source": [
        "# Accessing Zara Profile \n",
        "L = instaloader.Instaloader()\n",
        "user_name = 'zara'\n",
        "profile = instaloader.Profile.from_username(L.context, user_name)\n",
        "\n",
        "# Converting to DF\n",
        "posts_df = pd.DataFrame(columns=['num_comments', 'num_likes', 'caption', 'image_url', 'is_video'])\n",
        "\n",
        "# URL of Zara's Instagram\n",
        "url = 'https://www.instagram.com/p/{}/'\n",
        "\n",
        "# Grabbing 700 posts \n",
        "posts = profile.get_posts()\n",
        "posts_scrape = 700\n",
        "number = 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrnEc1WslPL-"
      },
      "source": [
        "# Scraping # of comments, # of likes, caption, image_url, is_video\n",
        "for post in posts:\n",
        "    if number < posts_scrape:\n",
        "        number += 1\n",
        "        posts_df = posts_df.append({'num_comments': post.comments,\n",
        "                                    'num_likes': post.likes,\n",
        "                                    'caption': post.caption,\n",
        "                                    'image_url': post.url, \n",
        "                                    'is_video': post.is_video}, ignore_index=True)\n",
        "        posts_df.is_video.astype('bool')\n",
        "        if posts_df[posts_df.is_video == False].shape[0] == posts_scrape:\n",
        "            number = posts_scrape      \n",
        "    else:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGXbFfQDlcNE"
      },
      "source": [
        "# Only grabbing posts by dropping any values where is_video column is true\n",
        "posts_df = posts_df[posts_df['is_video'] == False]\n",
        "# Dropping is_video column as it is no longer  needed\n",
        "posts_df = posts_df.drop('is_video', 1)\n",
        "# Exporting as CSV\n",
        "posts_df.to_csv('insta.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lleoc0GWEA5",
        "outputId": "500a6929-3c4d-43cc-e371-5ca70add9fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "posts_df = posts_df.reset_index(drop=True)\n",
        "posts_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_comments</th>\n",
              "      <th>num_likes</th>\n",
              "      <th>caption</th>\n",
              "      <th>image_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>421</td>\n",
              "      <td>73609</td>\n",
              "      <td>FW20 Campaign. Kids Collection\\nCreative Direc...</td>\n",
              "      <td>https://scontent-dfw5-2.cdninstagram.com/v/t51...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>126</td>\n",
              "      <td>38690</td>\n",
              "      <td>FW20 Campaign. Kids Collection\\nCreative Direc...</td>\n",
              "      <td>https://scontent-dfw5-2.cdninstagram.com/v/t51...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>196</td>\n",
              "      <td>56404</td>\n",
              "      <td>FW20 Campaign. Kids Collection\\nCreative Direc...</td>\n",
              "      <td>https://scontent-dfw5-2.cdninstagram.com/v/t51...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>34923</td>\n",
              "      <td>FW20 Campaign. Man Collection\\nCreative Direct...</td>\n",
              "      <td>https://scontent-dfw5-2.cdninstagram.com/v/t51...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>189</td>\n",
              "      <td>34424</td>\n",
              "      <td>FW20 Campaign. Man Collection\\nCreative Direct...</td>\n",
              "      <td>https://scontent-dfw5-2.cdninstagram.com/v/t51...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  num_comments num_likes                                            caption  \\\n",
              "0          421     73609  FW20 Campaign. Kids Collection\\nCreative Direc...   \n",
              "1          126     38690  FW20 Campaign. Kids Collection\\nCreative Direc...   \n",
              "2          196     56404  FW20 Campaign. Kids Collection\\nCreative Direc...   \n",
              "3          106     34923  FW20 Campaign. Man Collection\\nCreative Direct...   \n",
              "4          189     34424  FW20 Campaign. Man Collection\\nCreative Direct...   \n",
              "\n",
              "                                           image_url  \n",
              "0  https://scontent-dfw5-2.cdninstagram.com/v/t51...  \n",
              "1  https://scontent-dfw5-2.cdninstagram.com/v/t51...  \n",
              "2  https://scontent-dfw5-2.cdninstagram.com/v/t51...  \n",
              "3  https://scontent-dfw5-2.cdninstagram.com/v/t51...  \n",
              "4  https://scontent-dfw5-2.cdninstagram.com/v/t51...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTvluaE9nZ3V"
      },
      "source": [
        "## Obtaining Image Labels From Google Vision Cloud\n",
        "\n",
        "### Accessing the Google Vision API to detect and classify photo labels for each image in our dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRxtl0HCnbFa"
      },
      "source": [
        "#!pip install google-cloud-vision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwpIvKlzuGk2"
      },
      "source": [
        "from google.cloud import vision\n",
        "import os\n",
        "\n",
        "\"\"\"Initialize Environment Variables to enable authentication with google Vision API\"\"\"\n",
        "#credential_path = r\"C:\\Users\\india\\Documents\\text-assignment3-94cea931a4be.json\" \n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credential_path\n",
        "\n",
        "client = vision.ImageAnnotatorClient()\n",
        "image = vision.Image() \n",
        "\n",
        "\"\"\"storing urls for each image and file names\"\"\"\n",
        "file_name=[]\n",
        "labels=[]\n",
        "image_paths = []\n",
        "counter=0\n",
        "\n",
        "for each_img in posts_df.image_url:\n",
        "  image_paths.append(each_img)\n",
        "  file_name.append(str(posts_df.image_url.index[counter]+1) + \".jpg\")\n",
        "  counter+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n4AVlFh2Ipw"
      },
      "source": [
        "def getlabelsforRemoteImage(uri):\n",
        "    \"\"\"Detects labels in the file located in Google Cloud Storage or on the\n",
        "    Web.\"\"\"\n",
        "    labels_list=[]\n",
        "    image.source.image_uri = uri\n",
        "\n",
        "    response = client.label_detection(image=image)\n",
        "    labels = response.label_annotations\n",
        "    \n",
        "    for label in labels:\n",
        "        labels_list.append(label.description)\n",
        "    print(uri)\n",
        "    print(labels_list)\n",
        "    return(labels_list)\n",
        "\n",
        "\"\"\"grabbing photo labels for each image url in our dataset\"\"\"\n",
        "for i in image_paths:\n",
        "    labels.append(getlabelsforRemoteImage(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rxfIzlqDriO"
      },
      "source": [
        "posts_df['labels']=pd.Series(labels) #storing labels in our dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBQ1Iezl9cxk"
      },
      "source": [
        "## Measuring Engagement\n",
        "\n",
        "### We created a metric for engagement using a weighted sum of the number of likes and number of comments per post. We used min-max scaling to normalize these variables and assigned a weight of 0.4 to the number of likes and 0.6 to the number of comments. Comments were assigned a greater weight as they indicate the user engaged more actively with the post. \n",
        "\n",
        "### A binary engagement score was assigned to each post with a value of 1 if the engagement score is above the median engagement score and a value of 0 if below. This allows our metric for engagement to be relative to the posts we scraped. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ueKAFm9cPq"
      },
      "source": [
        "# Scaling Likes and Comments\n",
        "posts_df['scaled_likes'] = posts_df['num_likes'] / posts_df['num_likes'].max()\n",
        "posts_df['scaled_comms'] = posts_df['num_comments'] / posts_df['num_comments'].max()\n",
        "\n",
        "# Creating Engagement Score\n",
        "posts_df['engagement_score'] = .4 * posts_df['scaled_likes'] + .6 * posts_df['scaled_comms']\n",
        "\n",
        "# Qualitative 'High' or 'Low'\n",
        "def engagement_qual(eng_score):\n",
        "    if eng_score > posts_df['engagement_score'].median():\n",
        "        return 'High'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "# Binary 1 or 0 to perform other tasks\n",
        "def engagement_bin(eng_score):\n",
        "    if eng_score > posts_df['engagement_score'].median():\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtIv-GTaXVd5"
      },
      "source": [
        "#Creating Engagement Columns\n",
        "posts_df['engagement'] = posts_df['engagement_score'].apply(engagement_bin)\n",
        "posts_df['engagement_qual'] = posts_df['engagement_score'].apply(engagement_qual)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_WRMzz6VAKn",
        "outputId": "7bb6320e-9b80-4644-937b-95b64a3c30c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "posts_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_comments</th>\n",
              "      <th>num_likes</th>\n",
              "      <th>caption</th>\n",
              "      <th>image_url</th>\n",
              "      <th>labels</th>\n",
              "      <th>scaled_likes</th>\n",
              "      <th>scaled_comms</th>\n",
              "      <th>engagement_score</th>\n",
              "      <th>engagement</th>\n",
              "      <th>engagement_qual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>405</td>\n",
              "      <td>73222</td>\n",
              "      <td>FW20 Campaign. Kids Collection\\nCreative Direc...</td>\n",
              "      <td>https://scontent-iad3-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>['Clothing', 'Fashion', 'Outerwear', 'Fur', 'S...</td>\n",
              "      <td>0.249823</td>\n",
              "      <td>0.124769</td>\n",
              "      <td>0.174791</td>\n",
              "      <td>1</td>\n",
              "      <td>High</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>124</td>\n",
              "      <td>38537</td>\n",
              "      <td>FW20 Campaign. Kids Collection\\nCreative Direc...</td>\n",
              "      <td>https://scontent-iad3-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>['Sky', 'Darkness', 'Room', 'Adventure game', ...</td>\n",
              "      <td>0.131483</td>\n",
              "      <td>0.038201</td>\n",
              "      <td>0.075514</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>194</td>\n",
              "      <td>56141</td>\n",
              "      <td>FW20 Campaign. Kids Collection\\nCreative Direc...</td>\n",
              "      <td>https://scontent-iad3-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>['Cool', 'Fashion', 'Jeans', 'Sitting', 'Denim...</td>\n",
              "      <td>0.191545</td>\n",
              "      <td>0.059766</td>\n",
              "      <td>0.112478</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>104</td>\n",
              "      <td>34764</td>\n",
              "      <td>FW20 Campaign. Man Collection\\nCreative Direct...</td>\n",
              "      <td>https://scontent-iad3-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>['Hair', 'Face', 'Hairstyle', 'Eyebrow', 'Fore...</td>\n",
              "      <td>0.118610</td>\n",
              "      <td>0.032039</td>\n",
              "      <td>0.066668</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "      <td>34312</td>\n",
              "      <td>FW20 Campaign. Man Collection\\nCreative Direct...</td>\n",
              "      <td>https://scontent-iad3-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>['Snapshot', 'Standing', 'Hand', 'Arm', 'Human...</td>\n",
              "      <td>0.117068</td>\n",
              "      <td>0.057609</td>\n",
              "      <td>0.081393</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_comments  num_likes  ... engagement engagement_qual\n",
              "0           405      73222  ...          1            High\n",
              "1           124      38537  ...          0             Low\n",
              "2           194      56141  ...          0             Low\n",
              "3           104      34764  ...          0             Low\n",
              "4           187      34312  ...          0             Low\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Nb6C_1Qowg"
      },
      "source": [
        "posts_df.to_csv('insta_labels.csv', index=False) #saving to csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b61Kvx-CYD4T"
      },
      "source": [
        "## Predicting Engagement\n",
        "\n",
        "### We used three models to predict engagement using TF-IDF scores. TF-IDF scores calculate the frequency with which a word was used within one body of text relative to all the text data one has. It is a helpful tool to find key, relevant words within text documents. Using TF-IDF in this context helps us identify which key labels or words within a caption clearly distinguish the post and contribute to the user's engagement with the post. \n",
        "\n",
        "### 1. Our first model predicted engagement using just image labels. \n",
        "### 2. Our second model predicted engagement using just captions. \n",
        "### 3. Our third model predicted engagement using both image labels and captions.\n",
        "\n",
        "### The confusion matrix and classifcation matrix for each model is outputted below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LCqbk5QYFBi"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def predicting_eng(X,y):\n",
        "  \"\"\" logistic regression model using 80% train, 20% test split\"\"\"\n",
        "  X_train, X_test, y_train,y_test = train_test_split(X,y,test_size= 0.2, random_state=1)\n",
        "\n",
        "  \"\"\"initialize TFIDFVectorizer\"\"\"\n",
        "  tfidf_vectorizer = TfidfVectorizer(stop_words='english',use_idf=True)\n",
        "  fitted_vectorizer=tfidf_vectorizer.fit(X_train)\n",
        "  X_train_tfidf=fitted_vectorizer.transform(X_train)\n",
        "  X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "  \"\"\"fitting logistic regression model to data \"\"\"\n",
        "\n",
        "  model = LogisticRegression()\n",
        "  model.fit(X_train_tfidf,y_train)\n",
        "\n",
        "  \"\"\" Predicting on test data\"\"\" \n",
        "  y_fitted = model.predict(X_test_tfidf)\n",
        "\n",
        "  \"\"\"confusion matrix\"\"\"\n",
        "  print(confusion_matrix(y_test,y_fitted))\n",
        "  \n",
        "  \"\"\"classification report\"\"\"\n",
        "  print(classification_report(y_test,y_fitted))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmiqe8SxOLgz"
      },
      "source": [
        "### Predicting engagement using only image labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJU6auZCM2ta",
        "outputId": "68e028b7-5b2f-4dc8-c408-cb53acf12466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "X = posts_df['labels']\n",
        "y = posts_df['engagement']\n",
        "print(\"Confusion Matrix and Classification Report: \")\n",
        "predicting_eng(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix and Classification Report: \n",
            "[[32 25]\n",
            " [17 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.56      0.60        57\n",
            "           1       0.62      0.70      0.66        57\n",
            "\n",
            "    accuracy                           0.63       114\n",
            "   macro avg       0.63      0.63      0.63       114\n",
            "weighted avg       0.63      0.63      0.63       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2TfbBEfPhnB"
      },
      "source": [
        "### Predicting engagement using only captions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri25xUMKOY8O",
        "outputId": "df416ad2-3af9-47a6-d284-2bbfa0e0a5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "X = posts_df['caption']\n",
        "y = posts_df['engagement']\n",
        "print(\"Confusion Matrix and Classification Report: \")\n",
        "predicting_eng(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix and Classification Report: \n",
            "[[38 19]\n",
            " [16 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.67      0.68        57\n",
            "           1       0.68      0.72      0.70        57\n",
            "\n",
            "    accuracy                           0.69       114\n",
            "   macro avg       0.69      0.69      0.69       114\n",
            "weighted avg       0.69      0.69      0.69       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPvXcRGHVbjA"
      },
      "source": [
        "### Predicting engagement using a combination of captions and image labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHEZxovyVfFA",
        "outputId": "c8d33ff7-d3c9-4498-d4a1-e970d69b7a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "posts_df['caption_labels'] = posts_df['caption'] + ' ' + posts_df['labels']\n",
        "X = posts_df['caption_labels']\n",
        "y = posts_df['engagement']\n",
        "print(\"Confusion Matrix and Classification Report: \")\n",
        "predicting_eng(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix and Classification Report: \n",
            "[[35 22]\n",
            " [14 43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.61      0.66        57\n",
            "           1       0.66      0.75      0.70        57\n",
            "\n",
            "    accuracy                           0.68       114\n",
            "   macro avg       0.69      0.68      0.68       114\n",
            "weighted avg       0.69      0.68      0.68       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKrDfcWyVg5L"
      },
      "source": [
        "### Interpreting Our Models\n",
        "\n",
        "The engagement score was calculated by taking a weighted percentage of the number of likes and comments on a post. We set the engagement score to be equal to 1 if the users level of engagement with a post was greater than the median level for all posts. It was set to 0 if it was less than this value. This allowed our dataset to be equally balanced between the two engagement classes.\n",
        "\n",
        "When predicting engagement using only image labels, our model correctly classified 65% of posts that had an engagement of 0 and 62% that had an engagement of 1. When using only captions, we correctly classified 70% of posts with an engagement score of 0 and 68% with an engagement of 1. When combining the two, we correctly classified 71% of posts with low engagement and 66% of posts with high engagement.\n",
        "\n",
        "From these results, we can infer that using captions to predict engagement greatly increased our model's accuracy. Using both captions and labels helped improve the model's accuracy for posts with low engagement but only slightly. It decreased the model's predictive ability for posts with high engagement. This suggests that captions are very influential on a user's engagement with a post and carry more weight than the topics depicted within the image. Zara will be able to increase user response to posts by focusing on creating engaging captions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WTgerdZeVWZ"
      },
      "source": [
        "## Topic modeling (LDA) on the image labels.\n",
        "\n",
        "#### LDA topic modeling identifies the hidden semantic structure in our images. It's a probabilistic, unsupervised approach that clusters similar documents dependent upon the topics they share. These topics are identified recursively through finding which topics yield the highest probability for being generated from the labels within a given image.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL1JS4LN7wD_"
      },
      "source": [
        "!pip install pyLDAvis \n",
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE2hYG9V7wEB",
        "outputId": "1cfbdc6a-1a27-4ce9-da1b-a4d4974121cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import ast\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer \n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsrbRah07wEN"
      },
      "source": [
        "### Pre-Processing Image Labels\n",
        "\n",
        "### We cleaned our image labels by removing stopwords and lemmatizing the words. Lemmatizing is the process of reducing the word to its root or base word. For example, it will convert 'is' and 'are' to 'be' or 'walks' and 'walking' to 'walk'. This will help us easily compare topics when we apply LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERInVUty7wEN"
      },
      "source": [
        "def lemmatize(text):\n",
        "  ''' returns lemmatized root word of all words'''\n",
        "  return WordNetLemmatizer().lemmatize(text, pos='v')\n",
        "    \n",
        "def preprocess(text):\n",
        "  ''' iterates through each word in the text, removes all stopwords, and returns a list of all lemmatized words'''\n",
        "  result = []\n",
        "  for token in gensim.utils.simple_preprocess(text):\n",
        "      if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
        "          result.append(lemmatize(token))\n",
        "  return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA4canjg7wEP"
      },
      "source": [
        "clean_labels = posts_df['labels'].map(preprocess)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ajjRSIS7wEQ"
      },
      "source": [
        "### Building a Bag of Words\n",
        "\n",
        "### We will run our topic modeling using a bag of words approach. This creates a list of words and their corresponding frequencies. We will soon feed this to our LDA model so that the model can identify which photo labels are most important. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8_-71U97wER"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(clean_labels) #creating a dictionary with our topics and their frequencies\n",
        "dictionary.filter_extremes(no_below=7, no_above=0.5, keep_n=100000) #removing any potential outlier topics to prevent them from over-influencing our model\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in clean_labels] #creating the bag of words corpus = list of tuples references index of topic in our dictionary and frequency count"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V1qTcGl7wEX"
      },
      "source": [
        "### Running LDA On Image Labels To Identify Significant Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axeMNPJo7wEX"
      },
      "source": [
        "np.random.seed(2020)\n",
        "\n",
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=8, id2word=dictionary, passes=8, workers=2) #setting up LDA model using our bag of words and dictionary for topics "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRaQx-sRrcON",
        "outputId": "1ec5dfa4-aaf5-4268-fd43-18f431d7d098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def clean_topics(string): \n",
        "  string = re.sub('[^A-Za-z ]+','', string)\n",
        "  ''' returns cleaned topics by removing any punctuation and splitting on spaces to format into a list'''\n",
        "  words = list(string.split(\"  \")) \n",
        "  return words \n",
        "\n",
        "topic_words={} #dictionary to store words in each topic\n",
        "for topic, word in lda_model.show_topics():\n",
        "    topic_words[topic]=clean_topics(word) #filling in dictionary with cleaned topic for each topic number\n",
        "    print('Topic Number:',topic,'\\nWords:',topic_words[topic])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic Number: 0 \n",
            "Words: ['hair', 'beauty', 'hairstyle', 'skin', 'long', 'child', 'face', 'model', 'chin', 'photography']\n",
            "Topic Number: 1 \n",
            "Words: ['photography', 'black', 'white', 'monochrome', 'fashion', 'photograph', 'stand', 'blue', 'denim', 'jeans']\n",
            "Topic Number: 2 \n",
            "Words: ['leg', 'human', 'sit', 'photography', 'footwear', 'joint', 'fashion', 'shoulder', 'shoe', 'arm']\n",
            "Topic Number: 3 \n",
            "Words: ['design', 'eyewear', 'uniform', 'glass', 'cool', 'sunglasses', 'room', 'shoe', 'product', 'sandal']\n",
            "Topic Number: 4 \n",
            "Words: ['clothe', 'neck', 'shoulder', 'shirt', 'sleeve', 'blue', 'fashion', 'outerwear', 'jeans', 'white']\n",
            "Topic Number: 5 \n",
            "Words: ['fashion', 'clothe', 'model', 'coat', 'outerwear', 'beauty', 'shoot', 'photo', 'shoulder', 'bag']\n",
            "Topic Number: 6 \n",
            "Words: ['fashion', 'clothe', 'outerwear', 'dress', 'shoulder', 'model', 'sleeve', 'design', 'white', 'neck']\n",
            "Topic Number: 7 \n",
            "Words: ['fashion', 'outerwear', 'wear', 'formal', 'suit', 'photography', 'blazer', 'clothe', 'vehicle', 'stand']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3fbO0EVreaq"
      },
      "source": [
        "### Interpreting Topics\n",
        "\n",
        "The labels that were given the most weight are featured in the beginning of each list. This helps us identify what labels each topic found most significant.  \n",
        "\n",
        "Topic 0 is related to images that focus on the head, emphasizing the face, hair, and skin. \n",
        "\n",
        "Topic 1 captures black and white photography featuring jeans. \n",
        "\n",
        "Topic 2 appears to be capturing full body images of someone sitting down, highlighting their footwear. \n",
        "\n",
        "Topic 3 is focused on accessory products; glasses and shoes. \n",
        "\n",
        "Topic 4 is seems related to images that feature white tops and blue jeans. \n",
        "\n",
        "Topic 5 captures models dressed up for walking outside; wearing coats while holding bags. \n",
        "\n",
        "Topic 6 is very similar to topic 5, but has more of a focus on images that contain dresses as opposed to bags. \n",
        "\n",
        "Topic 7 captures images of models in work outfits; wearing suits and blazers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm7y8fJr7wEi"
      },
      "source": [
        "### Looking into the weight given to each topic for each image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfwuSK_XwWhE"
      },
      "source": [
        "data_labels = posts_df[['labels']]\n",
        "data_labels['index'] = data_labels.index\n",
        "\n",
        "#grabbing topic name and associated weight for each image\n",
        "for i in range(0,len(bow_corpus)):\n",
        "    for index, score in sorted(lda_model[bow_corpus[i]]):\n",
        "        arr = \"Topic \"+ str(index)\n",
        "        data_labels.loc[i,arr]= score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW1aodnTWFRi",
        "outputId": "c66d6cae-4100-48e4-dafc-9d2d75509331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "#Displaying topic weights for each images label\n",
        "data_labels[1:10]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>index</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 5</th>\n",
              "      <th>Topic 6</th>\n",
              "      <th>Topic 0</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 3</th>\n",
              "      <th>Topic 4</th>\n",
              "      <th>Topic 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Sky', 'Darkness', 'Room', 'Adventure game', ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.031338</td>\n",
              "      <td>0.031256</td>\n",
              "      <td>0.031272</td>\n",
              "      <td>0.031292</td>\n",
              "      <td>0.031441</td>\n",
              "      <td>0.780802</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.031350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Cool', 'Fashion', 'Jeans', 'Sitting', 'Denim...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.015666</td>\n",
              "      <td>0.015646</td>\n",
              "      <td>0.015644</td>\n",
              "      <td>0.015633</td>\n",
              "      <td>0.718560</td>\n",
              "      <td>0.187564</td>\n",
              "      <td>0.015646</td>\n",
              "      <td>0.015640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Hair', 'Face', 'Hairstyle', 'Eyebrow', 'Fore...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.011374</td>\n",
              "      <td>0.011366</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.920424</td>\n",
              "      <td>0.011365</td>\n",
              "      <td>0.011365</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.011366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Snapshot', 'Standing', 'Hand', 'Arm', 'Human...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.466011</td>\n",
              "      <td>0.012508</td>\n",
              "      <td>0.012504</td>\n",
              "      <td>0.012526</td>\n",
              "      <td>0.458934</td>\n",
              "      <td>0.012502</td>\n",
              "      <td>0.012501</td>\n",
              "      <td>0.012514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>['Clothing', 'Fashion', 'Outerwear', 'Beige', ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0.013891</td>\n",
              "      <td>0.013910</td>\n",
              "      <td>0.702047</td>\n",
              "      <td>0.013894</td>\n",
              "      <td>0.013894</td>\n",
              "      <td>0.013899</td>\n",
              "      <td>0.013897</td>\n",
              "      <td>0.214567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>['People in nature', 'Photograph', 'Black-and-...</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.932644</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>['Photograph', 'Standing', 'People', 'Suit', '...</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.471041</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.478937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>['Cool', 'Human', 'Font', 'Fur', 'Outerwear', ...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.010457</td>\n",
              "      <td>0.010435</td>\n",
              "      <td>0.398883</td>\n",
              "      <td>0.010471</td>\n",
              "      <td>0.010450</td>\n",
              "      <td>0.538442</td>\n",
              "      <td>0.010432</td>\n",
              "      <td>0.010430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>['Photograph', 'Clothing', 'Formal wear', 'Sta...</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.210490</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.731772</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              labels  index  ...   Topic 4   Topic 7\n",
              "1  ['Sky', 'Darkness', 'Room', 'Adventure game', ...      1  ...  0.031250  0.031350\n",
              "2  ['Cool', 'Fashion', 'Jeans', 'Sitting', 'Denim...      2  ...  0.015646  0.015640\n",
              "3  ['Hair', 'Face', 'Hairstyle', 'Eyebrow', 'Fore...      3  ...  0.011375  0.011366\n",
              "4  ['Snapshot', 'Standing', 'Hand', 'Arm', 'Human...      4  ...  0.012501  0.012514\n",
              "5  ['Clothing', 'Fashion', 'Outerwear', 'Beige', ...      5  ...  0.013897  0.214567\n",
              "6  ['People in nature', 'Photograph', 'Black-and-...      6  ...       NaN       NaN\n",
              "7  ['Photograph', 'Standing', 'People', 'Suit', '...      7  ...       NaN  0.478937\n",
              "8  ['Cool', 'Human', 'Font', 'Fur', 'Outerwear', ...      8  ...  0.010432  0.010430\n",
              "9  ['Photograph', 'Clothing', 'Formal wear', 'Sta...      9  ...       NaN  0.731772\n",
              "\n",
              "[9 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgdNQFPhu1k8"
      },
      "source": [
        "### Identifying the most dominant topic for each image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwP-ukB6Sz1"
      },
      "source": [
        "\n",
        "def top_topics(lda_model=None, corpus=bow_corpus, texts=clean_labels):\n",
        "  ''' returns best topic match for each document and the corresponding score'''\n",
        "\n",
        "  topics = pd.DataFrame() #creating empty dataframe to store topics\n",
        "\n",
        "  # Get main topic in each document\n",
        "  for i, row_list in enumerate(lda_model[bow_corpus])\n",
        "      row = row_list[0] if lda_model.per_word_topics else row_list            \n",
        "      row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "      # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "      for j, (topic_num, prop_topic) in enumerate(row):\n",
        "          if j == 0:  # => dominant topic\n",
        "              wp = lda_model.show_topic(topic_num)\n",
        "              topic_keywords = \", \".join([word for word, prop in wp])\n",
        "              topics = topics.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "          else:\n",
        "              break\n",
        "\n",
        "  topics.columns = ['Dominant Topic', 'Percent Contribution', 'Keywords']\n",
        "\n",
        "  # Add original text to the end of the output\n",
        "  contents = pd.Series(texts)\n",
        "  topics = pd.concat([topics, contents], axis=1)\n",
        "  return topics "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOEWUSf3udbR"
      },
      "source": [
        "dominant_topics = top_topics(lda_model, corpus=bow_corpus, texts=clean_labels)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr9H4DTxunJA",
        "outputId": "b1b6c14b-b85f-4724-d820-eafd61cf9f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "dominant_topics"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Percent Contribution</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.6099</td>\n",
              "      <td>fashion, clothe, outerwear, dress, shoulder, m...</td>\n",
              "      <td>[clothe, fashion, outerwear, fur, street, fash...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.7808</td>\n",
              "      <td>design, eyewear, uniform, glass, cool, sunglas...</td>\n",
              "      <td>[sky, darkness, room, adventure, game, music, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7185</td>\n",
              "      <td>photography, black, white, monochrome, fashion...</td>\n",
              "      <td>[cool, fashion, jeans, sit, denim, shoe, style]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9204</td>\n",
              "      <td>hair, beauty, hairstyle, skin, long, child, fa...</td>\n",
              "      <td>[hair, face, hairstyle, eyebrow, forehead, chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.4662</td>\n",
              "      <td>leg, human, sit, photography, footwear, joint,...</td>\n",
              "      <td>[snapshot, stand, hand, arm, human, photograph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.8138</td>\n",
              "      <td>fashion, clothe, outerwear, dress, shoulder, m...</td>\n",
              "      <td>[clothe, fashion, fashion, model, footwear, fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>hair, beauty, hairstyle, skin, long, child, fa...</td>\n",
              "      <td>[hair, face, hairstyle, beauty, lip, skin, fas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.4669</td>\n",
              "      <td>fashion, outerwear, wear, formal, suit, photog...</td>\n",
              "      <td>[leg, footwear, street, fashion, photography, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.3376</td>\n",
              "      <td>fashion, clothe, model, coat, outerwear, beaut...</td>\n",
              "      <td>[pink, fashion, street, fashion, outerwear, gl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.4930</td>\n",
              "      <td>fashion, clothe, model, coat, outerwear, beaut...</td>\n",
              "      <td>[clothe, street, fashion, white, jeans, fashio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Dominant Topic  ...                                             labels\n",
              "0               6.0  ...  [clothe, fashion, outerwear, fur, street, fash...\n",
              "1               3.0  ...  [sky, darkness, room, adventure, game, music, ...\n",
              "2               1.0  ...    [cool, fashion, jeans, sit, denim, shoe, style]\n",
              "3               0.0  ...  [hair, face, hairstyle, eyebrow, forehead, chi...\n",
              "4               2.0  ...  [snapshot, stand, hand, arm, human, photograph...\n",
              "..              ...  ...                                                ...\n",
              "565             6.0  ...  [clothe, fashion, fashion, model, footwear, fa...\n",
              "566             0.0  ...  [hair, face, hairstyle, beauty, lip, skin, fas...\n",
              "567             7.0  ...  [leg, footwear, street, fashion, photography, ...\n",
              "568             5.0  ...  [pink, fashion, street, fashion, outerwear, gl...\n",
              "569             5.0  ...  [clothe, street, fashion, white, jeans, fashio...\n",
              "\n",
              "[570 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvbpcFfK7wEq"
      },
      "source": [
        "### Engagement scores vs Topic Weights: Splitting the engagement scores into quartiles to identify the highest and lowest score quartiles. We then analyzed the proportion of each topic within each quartile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci9GnWEN7wEq",
        "outputId": "2eddf3f7-15b5-4b88-e426-c6bac65602a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_labels['image_URL'] = posts_df['image_url']\n",
        "cols = ['image_URL','labels','index','Topic 0','Topic 1','Topic 2','Topic 3','Topic 4','Topic 5','Topic 6','Topic 7']\n",
        "data_labels[cols].to_csv('topics_and_weights.csv')\n",
        "data_labels['engagement_score'] = posts_df['engagement_score']\n",
        "data_labels.engagement_score.quantile([0.25,0.5,0.75])\n",
        "#identifying engagement scores for each quartile"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25    0.095768\n",
              "0.50    0.132158\n",
              "0.75    0.198502\n",
              "Name: engagement_score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe-Nrb_57wEs"
      },
      "source": [
        "#Splitting the data into two quartiles for the lowest and highest engageent scores\n",
        "quart_25 = data_labels[data_labels['engagement_score']<0.095768] #lowest\n",
        "quart_75 = data_labels[data_labels['engagement_score']>0.198502] #highest\n",
        "\n",
        "#Average of topic weights in each of these quartiles\n",
        "avg_low = pd.DataFrame(quart_25[['Topic 0','Topic 1','Topic 2','Topic 3','Topic 4','Topic 5','Topic 6','Topic 7']].mean())\n",
        "avg_low = avg_low.transpose()\n",
        "\n",
        "avg_high = pd.DataFrame(quart_75[['Topic 0','Topic 1','Topic 2','Topic 3','Topic 4','Topic 5','Topic 6','Topic 7']].mean())\n",
        "avg_high = avg_high.transpose()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN915EWL7wEu",
        "outputId": "b5fca67a-fe53-4c84-a606-6dbb58325554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "eng_by_topic= avg_low.append(avg_high,ignore_index=True)\n",
        "eng_by_topic['Engagement_levels'] = ['Low Engagement','High Engagement']\n",
        "eng_by_topic.set_index('Engagement_levels',inplace=True)\n",
        "eng_by_topic"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 0</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "      <th>Topic 4</th>\n",
              "      <th>Topic 5</th>\n",
              "      <th>Topic 6</th>\n",
              "      <th>Topic 7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Engagement_levels</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Low Engagement</th>\n",
              "      <td>0.159203</td>\n",
              "      <td>0.185159</td>\n",
              "      <td>0.126910</td>\n",
              "      <td>0.105928</td>\n",
              "      <td>0.082690</td>\n",
              "      <td>0.093169</td>\n",
              "      <td>0.180964</td>\n",
              "      <td>0.170946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High Engagement</th>\n",
              "      <td>0.177665</td>\n",
              "      <td>0.097137</td>\n",
              "      <td>0.172274</td>\n",
              "      <td>0.048284</td>\n",
              "      <td>0.139917</td>\n",
              "      <td>0.156746</td>\n",
              "      <td>0.274314</td>\n",
              "      <td>0.100644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Topic 0   Topic 1   Topic 2  ...   Topic 5   Topic 6   Topic 7\n",
              "Engagement_levels                                ...                              \n",
              "Low Engagement     0.159203  0.185159  0.126910  ...  0.093169  0.180964  0.170946\n",
              "High Engagement    0.177665  0.097137  0.172274  ...  0.156746  0.274314  0.100644\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKN4v6ac7wEw"
      },
      "source": [
        "### LDA Visualisation: a fun interactive visual to explore the topics and identify the differences between them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwoBdB2G7wEw",
        "outputId": "e5f813ef-268d-4fa9-9e85-fd857537bee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        }
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
        "vis"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1001406974487890006077534520\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1001406974487890006077534520_data = {\"mdsDat\": {\"x\": [-0.014303902347437645, 0.23022010946396484, -0.054142629873643225, 0.08062181189564166, -0.09469950595764141, -0.07670402294460468, 0.16659507446224486, -0.2375869346985248], \"y\": [0.10558325467668624, -0.2036519385434037, 0.04310346092276722, 0.11440290179131143, -0.12356356549605796, 0.1857738672008994, 0.037487104475905864, -0.15913508502810844], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [20.385327481024003, 16.14049294335242, 14.09702003091757, 12.069142901917049, 11.090296271429475, 10.825632590573555, 10.197071096952568, 5.1950166838333605]}, \"tinfo\": {\"Term\": [\"leg\", \"hair\", \"black\", \"photography\", \"clothe\", \"design\", \"fashion\", \"neck\", \"sleeve\", \"monochrome\", \"outerwear\", \"formal\", \"wear\", \"suit\", \"white\", \"shirt\", \"coat\", \"eyewear\", \"skin\", \"footwear\", \"blue\", \"sit\", \"blazer\", \"shoe\", \"dress\", \"cool\", \"shoulder\", \"hairstyle\", \"uniform\", \"face\", \"fur\", \"robe\", \"pattern\", \"green\", \"short\", \"dress\", \"leisure\", \"waist\", \"costume\", \"tree\", \"sleeve\", \"summer\", \"design\", \"beige\", \"headgear\", \"clothe\", \"outerwear\", \"fashion\", \"joint\", \"plant\", \"neck\", \"shoulder\", \"model\", \"footwear\", \"accessory\", \"yellow\", \"textile\", \"fun\", \"jacket\", \"style\", \"shoot\", \"photo\", \"white\", \"black\", \"stand\", \"leg\", \"beauty\", \"photography\", \"facial\", \"expression\", \"eye\", \"skin\", \"friendship\", \"eyebrow\", \"face\", \"child\", \"hair\", \"head\", \"nose\", \"long\", \"toddler\", \"cheek\", \"chin\", \"hairstyle\", \"smile\", \"lip\", \"forehead\", \"gesture\", \"hand\", \"blond\", \"brown\", \"ear\", \"beauty\", \"fun\", \"people\", \"sit\", \"arm\", \"muscle\", \"model\", \"shoot\", \"photo\", \"photography\", \"shoulder\", \"human\", \"neck\", \"fashion\", \"monochrome\", \"illustration\", \"light\", \"art\", \"photograph\", \"style\", \"black\", \"architecture\", \"portrait\", \"white\", \"denim\", \"stock\", \"photography\", \"people\", \"textile\", \"jeans\", \"cool\", \"text\", \"blue\", \"electric\", \"snapshot\", \"stand\", \"font\", \"tree\", \"gesture\", \"sit\", \"photo\", \"trousers\", \"street\", \"shoot\", \"fashion\", \"design\", \"beauty\", \"human\", \"model\", \"outerwear\", \"clothe\", \"bag\", \"dog\", \"trench\", \"canidae\", \"leather\", \"coat\", \"overcoat\", \"magenta\", \"pink\", \"purple\", \"street\", \"trousers\", \"jacket\", \"accessory\", \"model\", \"shoot\", \"snapshot\", \"photo\", \"yellow\", \"fashion\", \"pocket\", \"blond\", \"beauty\", \"outerwear\", \"clothe\", \"beige\", \"shoulder\", \"hand\", \"jeans\", \"blue\", \"hair\", \"stand\", \"footwear\", \"black\", \"white\", \"thigh\", \"knee\", \"body\", \"chair\", \"leg\", \"furniture\", \"muscle\", \"tights\", \"sportswear\", \"human\", \"high\", \"shoe\", \"arm\", \"sit\", \"joint\", \"footwear\", \"room\", \"costume\", \"brown\", \"stock\", \"hand\", \"leisure\", \"table\", \"purple\", \"plant\", \"toddler\", \"photography\", \"headgear\", \"shoot\", \"accessory\", \"photo\", \"stand\", \"shoulder\", \"dress\", \"child\", \"fashion\", \"white\", \"beauty\", \"black\", \"clothe\", \"vehicle\", \"suit\", \"blazer\", \"wear\", \"formal\", \"red\", \"sea\", \"vacation\", \"worker\", \"sky\", \"summer\", \"overcoat\", \"portrait\", \"fun\", \"street\", \"collar\", \"yellow\", \"snapshot\", \"outerwear\", \"jacket\", \"stand\", \"purple\", \"people\", \"stock\", \"coat\", \"photography\", \"smile\", \"architecture\", \"tights\", \"turquoise\", \"shoe\", \"fashion\", \"human\", \"clothe\", \"footwear\", \"beige\", \"white\", \"model\", \"design\", \"shirt\", \"turquoise\", \"pocket\", \"collar\", \"electric\", \"neck\", \"blue\", \"pink\", \"sleeve\", \"denim\", \"jeans\", \"ear\", \"trousers\", \"forehead\", \"magenta\", \"lip\", \"chin\", \"waist\", \"textile\", \"short\", \"shoulder\", \"nose\", \"worker\", \"cheek\", \"head\", \"clothe\", \"face\", \"eyebrow\", \"sportswear\", \"purple\", \"blond\", \"hairstyle\", \"outerwear\", \"white\", \"dress\", \"beauty\", \"fashion\", \"hair\", \"cool\", \"stand\", \"skin\", \"eyewear\", \"sunglasses\", \"product\", \"sandal\", \"ankle\", \"uniform\", \"glass\", \"equipment\", \"table\", \"font\", \"text\", \"room\", \"high\", \"sky\", \"shoe\", \"cool\", \"furniture\", \"design\", \"plant\", \"architecture\", \"pattern\", \"accessory\", \"chair\", \"sea\", \"footwear\", \"textile\", \"green\", \"headgear\", \"pink\", \"art\", \"leg\", \"beauty\", \"photography\", \"white\", \"outerwear\", \"fashion\"], \"Freq\": [122.0, 156.0, 128.0, 202.0, 212.0, 75.0, 393.0, 82.0, 71.0, 46.0, 177.0, 43.0, 43.0, 39.0, 164.0, 36.0, 44.0, 22.0, 47.0, 74.0, 61.0, 78.0, 30.0, 35.0, 102.0, 39.0, 147.0, 64.0, 20.0, 43.0, 16.490112333461767, 7.893360393739491, 22.128631046476098, 9.317909231847429, 6.004595597265618, 69.49716866096546, 5.7745255235176645, 19.131030968674906, 4.981155925549522, 7.696917491319893, 38.83263192050846, 10.195478116207111, 38.817852529599335, 21.692124467035462, 8.429966275829251, 98.81892609646708, 72.2665193719866, 158.89479113912992, 27.939045277069493, 4.536250345704719, 29.950839399327013, 51.898361557257594, 42.60237403310974, 22.39206953346974, 5.946203842629633, 7.711589025131465, 7.502586213177215, 6.9110588043517325, 9.824736659865195, 5.236971686387, 18.942407705828114, 18.892344201298357, 30.063651986282547, 24.01151317831722, 16.80811364812816, 19.67028083392677, 18.330671933930745, 16.277192527739853, 18.713391612706303, 13.727044760959123, 12.714083934277978, 40.47259078022641, 7.058814346506437, 18.57652599874705, 34.4335651851238, 36.72348269146437, 120.0618898654216, 12.007835993237745, 14.269317523926016, 37.094197871829394, 6.186085696324231, 8.604527231480919, 24.08499794711936, 45.848175565785965, 15.224886959934679, 22.628164036822476, 9.23873449481887, 6.228411386657662, 6.770931333818475, 21.739239533528707, 14.501612689568761, 4.414337556037955, 54.28131052643972, 9.523264263925295, 7.731810333320611, 20.76985128670436, 9.043559265542847, 2.3485095619169516, 29.109758241110157, 18.093944105403995, 17.54473451564483, 24.080444430367983, 17.46360012339795, 12.577523089419945, 13.085439208102377, 9.689650956892084, 45.29647057746824, 8.721090823540125, 8.271542821625056, 15.029711562693002, 33.13465367077417, 15.918225909118801, 87.78698450343904, 4.896499448103586, 7.271779427143112, 82.41904601016826, 18.131301821384973, 12.524739563456196, 91.56415446587721, 11.703532057796417, 10.877217793910527, 16.103179102330074, 14.733780979340063, 3.7684057443810772, 20.720297545142845, 5.318945980595718, 13.245216040715942, 24.821010030896435, 2.9304854606274278, 3.790577341146903, 2.6193447711710434, 15.20854458364455, 13.19383232254427, 1.8611887595375494, 6.12737427370669, 10.588265466003103, 33.57857144266319, 8.128521430281383, 10.809403219712406, 6.728053716341806, 7.780929996627391, 6.336897111949019, 5.841777639533804, 18.8481707035299, 16.94101275895424, 12.309271824800753, 6.6582607988128295, 17.938803516732467, 34.822309963474254, 12.342389508474042, 5.936500339654386, 11.0475027229141, 3.71409666980824, 17.742050614009322, 4.6866238430846945, 14.536354912625677, 7.436284997973025, 37.3101820681492, 24.502649917866414, 11.597594888928787, 24.269461118833757, 7.133748835562082, 95.02436764806217, 2.209993911950686, 9.628127308446402, 27.25323728994716, 32.484097216152534, 38.10768963553729, 7.670712268317997, 22.16757025691096, 1.6362471782077768, 4.838184552682078, 6.113918092334135, 12.503431788059226, 7.661515710767966, 5.456115244390627, 5.7762313723361185, 5.60370657727249, 13.76505355501042, 13.690640352612878, 10.29825964950816, 6.801002250477185, 89.7437841927002, 15.50180698838767, 6.713494197842211, 5.816622656373823, 7.121572797551752, 36.85329810189867, 4.414131088718153, 17.55775284688233, 16.65065790147318, 35.21495011286684, 28.474116344041757, 29.217458101207377, 10.579697992946166, 2.87840662004551, 8.750498954359317, 7.912846820710823, 3.086700871443001, 1.9616214854606582, 2.023773305323959, 1.6138241473055783, 2.0386078999500783, 1.3364672789256486, 31.47453116942898, 2.555247787670159, 12.17453931778525, 3.0443728783538364, 12.069677156739008, 11.667442117125143, 19.49662509180101, 11.719439304563315, 5.424532424682852, 21.200655665300253, 11.841069333860144, 7.8617782506070615, 6.49429205732094, 6.020431282299437, 19.633646031565625, 37.29417031069181, 27.958535341846, 39.19345554007891, 39.19218597563108, 9.271126801786018, 6.3515158519756545, 11.563712167087933, 5.404852720071522, 7.871484546243218, 7.904419654410695, 8.077044686542315, 4.973611209228247, 8.131579205746169, 13.165793200007581, 5.992753544247317, 7.85647625559973, 10.780293163125528, 41.28687482973458, 9.089032584492967, 17.776916434315783, 1.7106739846594163, 5.106543960495894, 4.738279887723771, 7.403850255847215, 31.793982023588498, 3.3650746302648584, 1.399382141965946, 1.2221257744613918, 2.1081664157583533, 4.519797620215752, 48.52564965296262, 8.886239632266019, 22.664644971732496, 8.898544318156146, 5.422492098956037, 12.119756172105754, 9.677579751496095, 5.152089585062042, 31.31061303330321, 11.9219917000926, 6.308469636911185, 13.797062629911926, 8.48597048368784, 37.99064423362567, 27.92786260417943, 10.940126113837586, 30.859165582792272, 15.105833967141374, 17.698307337038024, 3.255213905956454, 4.549220497876324, 4.776265301434522, 3.3442726005144054, 10.157551797415655, 8.79832803928055, 6.98633575233178, 6.54442491315793, 1.977716956793407, 32.85702403398966, 3.997979416041009, 1.7414518285356058, 2.2532794623303998, 3.0768740272575332, 40.597242103502346, 7.905569654767328, 3.8323476770511262, 1.6781083760389863, 1.2561593567004095, 5.840335715159479, 9.093248747196775, 21.00671110247385, 17.447913254058825, 11.99570084079295, 13.89991369873198, 22.322720899463175, 12.666496786683314, 5.060613423158802, 6.167518155070304, 5.101211461176097, 20.350916052386378, 12.865232488666974, 8.109163044047047, 8.059852933056252, 7.054195884337703, 17.545065229551778, 13.700281657255456, 5.836313508276698, 7.141347465768514, 6.067888762268744, 5.9626511246025995, 12.464330372442792, 3.6253575626555508, 4.869260488683863, 11.88457899283259, 13.128441319671618, 6.334918960443715, 20.469120718073675, 3.091537231077033, 2.4928628467269256, 4.660531734997456, 3.1828619552623483, 1.2359859580333263, 1.1314255198878314, 7.94538238410765, 2.9179164371980475, 1.3295590199308394, 1.4658257858101034, 1.8117310046015198, 1.3456422248562647, 5.195114120923917, 4.110895371419272, 4.535900293297028, 3.927067285714993, 3.189475588413739, 3.881892996484825], \"Total\": [122.0, 156.0, 128.0, 202.0, 212.0, 75.0, 393.0, 82.0, 71.0, 46.0, 177.0, 43.0, 43.0, 39.0, 164.0, 36.0, 44.0, 22.0, 47.0, 74.0, 61.0, 78.0, 30.0, 35.0, 102.0, 39.0, 147.0, 64.0, 20.0, 43.0, 18.858903639393795, 10.495390861643877, 30.376347549446145, 13.429353625987277, 8.721891475426222, 102.42837731864017, 8.581902176704821, 30.06029171884031, 8.616794365994116, 14.006839860164108, 71.4439157758645, 19.214801046926837, 75.67714604982046, 43.45307931239046, 17.502196904918875, 212.9109686141629, 177.49274897535747, 393.1183004009582, 69.20496745905562, 11.684129726949507, 82.1878702280042, 147.7966511964194, 128.69648109321946, 74.72343342863982, 21.262448673932205, 29.154230792828006, 28.641032491747524, 26.75496506746618, 39.89536417436503, 22.69561879568175, 84.87093055113459, 86.53953036681261, 164.4811587727004, 128.39704113952513, 85.36393688752959, 122.67619806535801, 136.76461579646886, 202.8960414790295, 19.987793574554434, 14.732017551676918, 13.668612260747635, 47.452868203858905, 8.362032348819435, 23.237431770661953, 43.350562719714134, 46.599026654634066, 156.2826689279573, 15.827342783158235, 19.012642507150716, 49.64143941081837, 8.296992599733489, 11.58795506311425, 33.860525137893234, 64.57956667921505, 22.43357586015383, 33.85787875736025, 14.78513246504602, 10.003250947734191, 12.210294849085056, 40.93893081188986, 27.547334903900154, 8.423931660645469, 136.76461579646886, 26.75496506746618, 27.830028165908363, 78.45455458444954, 34.5907512722994, 9.974418622776072, 128.69648109321946, 84.87093055113459, 86.53953036681261, 202.8960414790295, 147.7966511964194, 71.97936441673369, 82.1878702280042, 393.1183004009582, 46.43656288257184, 9.924345760897118, 9.970800786058335, 19.133572155321588, 43.71419887297897, 22.69561879568175, 128.39704113952513, 9.426107431558947, 14.103050048675689, 164.4811587727004, 36.63648714888649, 26.223041329881795, 202.8960414790295, 27.830028165908363, 28.641032491747524, 42.989491228485115, 39.486441167409026, 10.6486659861068, 61.1876692650673, 15.83036146918742, 40.5747362263258, 85.36393688752959, 10.825593560264515, 14.006839860164108, 10.003250947734191, 78.45455458444954, 86.53953036681261, 12.787587316012514, 44.61413864391924, 84.87093055113459, 393.1183004009582, 75.67714604982046, 136.76461579646886, 71.97936441673369, 128.69648109321946, 177.49274897535747, 212.9109686141629, 19.926232375271525, 18.02049734572179, 13.299204578330844, 7.610729798026591, 20.94567118132454, 44.82009648120857, 22.119021645079044, 10.822798915425501, 25.05256762379065, 8.804394660240016, 44.61413864391924, 12.787587316012514, 39.89536417436503, 21.262448673932205, 128.69648109321946, 84.87093055113459, 40.5747362263258, 86.53953036681261, 29.154230792828006, 393.1183004009582, 9.271635149501014, 40.93893081188986, 136.76461579646886, 177.49274897535747, 212.9109686141629, 43.45307931239046, 147.7966511964194, 12.210294849085056, 42.989491228485115, 61.1876692650673, 156.2826689279573, 85.36393688752959, 74.72343342863982, 128.39704113952513, 164.4811587727004, 14.731298197957825, 14.733041162215757, 11.824832514878876, 8.876787418793747, 122.67619806535801, 22.814383782067473, 9.974418622776072, 8.7965839198916, 10.932505317211229, 71.97936441673369, 8.971803074128832, 35.74301495282528, 34.5907512722994, 78.45455458444954, 69.20496745905562, 74.72343342863982, 27.157637142289715, 8.616794365994116, 27.547334903900154, 26.223041329881795, 12.210294849085056, 8.581902176704821, 10.06944427669839, 8.804394660240016, 11.684129726949507, 8.296992599733489, 202.8960414790295, 17.502196904918875, 84.87093055113459, 21.262448673932205, 86.53953036681261, 85.36393688752959, 147.7966511964194, 102.42837731864017, 46.599026654634066, 393.1183004009582, 164.4811587727004, 136.76461579646886, 128.39704113952513, 212.9109686141629, 20.68439429818297, 39.32082186198987, 30.47341952474649, 43.287148210096774, 43.28745417776926, 12.81416428672647, 8.887608724626025, 17.45754351999391, 8.889034244840994, 13.914288208498142, 19.214801046926837, 22.119021645079044, 14.103050048675689, 26.75496506746618, 44.61413864391924, 21.660315263274963, 29.154230792828006, 40.5747362263258, 177.49274897535747, 39.89536417436503, 85.36393688752959, 8.804394660240016, 27.830028165908363, 26.223041329881795, 44.82009648120857, 202.8960414790295, 22.43357586015383, 9.426107431558947, 8.7965839198916, 16.592920452106554, 35.74301495282528, 393.1183004009582, 71.97936441673369, 212.9109686141629, 74.72343342863982, 43.45307931239046, 164.4811587727004, 128.69648109321946, 75.67714604982046, 36.81095891936176, 16.592920452106554, 9.271635149501014, 21.660315263274963, 15.83036146918742, 82.1878702280042, 61.1876692650673, 25.05256762379065, 71.4439157758645, 36.63648714888649, 42.989491228485115, 8.423931660645469, 12.787587316012514, 14.78513246504602, 10.822798915425501, 33.85787875736025, 33.860525137893234, 30.06029171884031, 28.641032491747524, 8.721891475426222, 147.7966511964194, 19.012642507150716, 8.889034244840994, 11.58795506311425, 15.827342783158235, 212.9109686141629, 43.350562719714134, 23.237431770661953, 10.932505317211229, 8.804394660240016, 40.93893081188986, 64.57956667921505, 177.49274897535747, 164.4811587727004, 102.42837731864017, 136.76461579646886, 393.1183004009582, 156.2826689279573, 39.486441167409026, 85.36393688752959, 47.452868203858905, 22.332370697611374, 14.224035033296204, 9.130973813835286, 9.138718533601315, 8.112756938729397, 20.445171528778936, 16.081432884125668, 8.012792075102455, 10.06944427669839, 10.825593560264515, 10.6486659861068, 27.157637142289715, 8.971803074128832, 13.914288208498142, 35.74301495282528, 39.486441167409026, 22.814383782067473, 75.67714604982046, 11.684129726949507, 9.426107431558947, 30.376347549446145, 21.262448673932205, 8.876787418793747, 8.887608724626025, 74.72343342863982, 28.641032491747524, 13.429353625987277, 17.502196904918875, 25.05256762379065, 19.133572155321588, 122.67619806535801, 136.76461579646886, 202.8960414790295, 164.4811587727004, 177.49274897535747, 393.1183004009582], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.165599822998047, -4.902299880981445, -3.871500015258789, -4.736400127410889, -5.17579984664917, -2.727099895477295, -5.214900016784668, -4.017099857330322, -5.36269998550415, -4.927499771118164, -3.3090999126434326, -4.646399974822998, -3.309499979019165, -3.891400098800659, -4.836599826812744, -2.3750998973846436, -2.687999963760376, -1.9000999927520752, -3.6382999420166016, -5.456299781799316, -3.5687999725341797, -3.0190999507904053, -3.2165000438690186, -3.8596999645233154, -5.1855998039245605, -4.925600051879883, -4.953100204467773, -5.035200119018555, -4.683499813079834, -5.312600135803223, -4.0269999504089355, -4.029600143432617, -3.565000057220459, -3.789799928665161, -4.146500110626221, -3.989300012588501, -4.059800148010254, -4.178599834442139, -3.8055999279022217, -4.115499973297119, -4.192200183868408, -3.0343000888824463, -4.780600070953369, -3.812999963760376, -3.1958000659942627, -3.131500005722046, -1.9469000101089478, -4.249300003051758, -4.0767998695373535, -3.1214001178741455, -4.912600040435791, -4.582600116729736, -3.553299903869629, -2.9094998836517334, -4.011899948120117, -3.6157000064849854, -4.511499881744385, -4.905799865722656, -4.822199821472168, -3.6558001041412354, -4.0605998039245605, -5.25, -2.7407000064849854, -4.481100082397461, -4.689499855041504, -3.7014000415802, -4.532800197601318, -5.881100177764893, -3.363800048828125, -3.8392999172210693, -3.8701000213623047, -3.553499937057495, -3.874799966812134, -4.203000068664551, -4.163400173187256, -4.463799953460693, -2.78629994392395, -4.433800220489502, -4.486700057983398, -3.8894999027252197, -3.098900079727173, -3.8320000171661377, -2.1245999336242676, -5.011000156402588, -4.615499973297119, -2.187700033187866, -3.701900005340576, -4.071800231933594, -2.0824999809265137, -4.139599800109863, -4.212800025939941, -3.820499897003174, -3.90939998626709, -5.272900104522705, -3.5683999061584473, -4.928199768066406, -4.015900135040283, -3.3877999782562256, -5.5243000984191895, -5.267000198364258, -5.636600017547607, -3.877700090408325, -4.019800186157227, -5.978300094604492, -4.7866997718811035, -4.239799976348877, -3.085599899291992, -4.5040998458862305, -4.219099998474121, -4.69320011138916, -4.547800064086914, -4.7530999183654785, -4.834499835968018, -3.5078001022338867, -3.614500045776367, -3.933799982070923, -4.548299789428711, -3.5571999549865723, -2.893899917602539, -3.9312000274658203, -4.663099765777588, -4.041999816894531, -5.1321001052856445, -3.5683000087738037, -4.899499893188477, -3.7674999237060547, -4.43779993057251, -2.824899911880493, -3.2453999519348145, -3.9934000968933105, -3.255000114440918, -4.479400157928467, -1.8901000022888184, -5.651199817657471, -4.179500102996826, -3.1389999389648438, -2.9635000228881836, -2.803800106048584, -4.406799793243408, -3.345599889755249, -5.9517998695373535, -4.867700099945068, -4.633600234985352, -3.9182000160217285, -4.4079999923706055, -4.747499942779541, -4.690400123596191, -4.720799922943115, -3.737499952316284, -3.7428998947143555, -4.027599811553955, -4.442500114440918, -1.8626999855041504, -3.6187000274658203, -4.45550012588501, -4.598899841308594, -4.396500110626221, -2.752700090408325, -4.874800205230713, -3.4941000938415527, -3.5471999645233154, -2.798099994659424, -3.0106000900268555, -2.9848999977111816, -4.000699996948242, -5.3024001121521, -4.190499782562256, -4.291100025177002, -5.232500076293945, -5.685800075531006, -5.654699802398682, -5.88100004196167, -5.64739990234375, -6.0696001052856445, -2.910399913787842, -5.421500205993652, -3.860300064086914, -5.246300220489502, -3.8689000606536865, -3.9028000831604004, -3.389400005340576, -3.898400068283081, -4.668700218200684, -3.3055999279022217, -3.888000011444092, -4.297599792480469, -4.488699913024902, -4.564499855041504, -3.3582000732421875, -2.716599941253662, -3.004699945449829, -2.6670000553131104, -2.6670000553131104, -4.10860013961792, -4.486800193786621, -3.8875999450683594, -4.648200035095215, -4.272200107574463, -4.26800012588501, -4.246399879455566, -4.731299877166748, -4.239699840545654, -3.7578001022338867, -4.544899940490723, -4.274099826812744, -3.95770001411438, -2.6149001121520996, -4.128399848937988, -3.4576001167297363, -5.798600196838379, -4.704899787902832, -4.779799938201904, -4.333499908447266, -2.876199960708618, -5.122000217437744, -5.9994001388549805, -6.134900093078613, -5.589600086212158, -4.827000141143799, -2.453399896621704, -4.151000022888184, -3.2146999835968018, -4.149600028991699, -4.644899845123291, -3.84060001373291, -4.065700054168701, -4.696100234985352, -2.831700086593628, -3.797300100326538, -4.433800220489502, -3.65120005607605, -4.137199878692627, -2.6382999420166016, -2.946000099182129, -3.88319993019104, -2.8461999893188477, -3.5606000423431396, -3.4021999835968018, -5.095399856567383, -4.760700225830078, -4.711999893188477, -5.068399906158447, -3.95740008354187, -4.101099967956543, -4.331699848175049, -4.396999835968018, -5.593699932098389, -2.7834999561309814, -4.889900207519531, -5.720900058746338, -5.4633002281188965, -5.151700019836426, -2.571899890899658, -4.208099842071533, -4.932199954986572, -5.757999897003174, -6.047599792480469, -4.510900020599365, -4.0680999755859375, -3.230799913406372, -3.4163999557495117, -3.791100025177002, -3.6438000202178955, -3.1700000762939453, -3.7367000579833984, -4.654200077056885, -4.456399917602539, -4.646200180053711, -2.588099956512451, -3.0467000007629395, -3.5083000659942627, -3.514400005340576, -3.647599935531616, -2.7365000247955322, -2.983799934387207, -3.837100028991699, -3.6352999210357666, -3.7981998920440674, -3.815700054168701, -3.078399896621704, -4.313300132751465, -4.0183000564575195, -3.125999927520752, -3.0264999866485596, -3.755199909210205, -2.5822999477386475, -4.472599983215332, -4.68779993057251, -4.062099933624268, -4.44350004196167, -5.389400005340576, -5.477799892425537, -3.528700113296509, -4.530399799346924, -5.316400051116943, -5.218800067901611, -5.006999969482422, -5.3043999671936035, -3.9535000324249268, -4.187600135803223, -4.089200019836426, -4.233399868011475, -4.441400051116943, -4.244900226593018], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4561, 1.3054, 1.2736, 1.2249, 1.217, 1.2025, 1.1942, 1.1385, 1.0423, 0.9916, 0.9807, 0.9566, 0.9228, 0.8956, 0.8598, 0.8228, 0.6918, 0.6845, 0.6833, 0.6442, 0.5809, 0.5438, 0.4848, 0.3853, 0.3162, 0.2605, 0.2508, 0.2368, 0.189, 0.1239, 0.0906, 0.0685, -0.1091, -0.0862, -0.0347, -0.2401, -0.4193, -0.9326, 1.758, 1.7532, 1.7514, 1.6647, 1.6544, 1.6, 1.5936, 1.5857, 1.5602, 1.5477, 1.5368, 1.5325, 1.5302, 1.5262, 1.4832, 1.4813, 1.4362, 1.4209, 1.3536, 1.3501, 1.2342, 1.1909, 1.1822, 1.1776, 0.8998, 0.7909, 0.5431, 0.4948, 0.4823, 0.3776, 0.3375, 0.2783, 0.228, -0.3075, -0.3119, 0.0794, -0.0137, -1.8792, 1.9343, 1.83, 1.7724, 1.7178, 1.6821, 1.6045, 1.579, 1.3042, 1.2968, 1.2682, 1.2558, 1.2203, 1.1636, 1.093, 0.991, 0.9773, 0.9734, 0.9204, 0.8764, 0.8686, 0.8397, 0.724, 0.6525, 0.6522, 0.6192, 0.3185, 0.0784, 0.0319, -0.0261, -0.1222, -0.501, -0.2719, -0.5786, -0.4109, -0.8466, -1.3733, -1.6366, 2.0589, 2.0527, 2.0372, 1.9808, 1.9596, 1.8621, 1.5311, 1.514, 1.2957, 1.2514, 1.1924, 1.1108, 1.1049, 1.0639, 0.8763, 0.8722, 0.8622, 0.8431, 0.7068, 0.6945, 0.6805, 0.6671, 0.5014, 0.4163, 0.3941, 0.3802, 0.2173, 0.1046, -0.0699, -0.1889, -0.4111, -0.2962, -0.5025, -0.9869, -1.2648, 2.1313, 2.1257, 2.0609, 1.9327, 1.8865, 1.8127, 1.8032, 1.7855, 1.7705, 1.5297, 1.4898, 1.4882, 1.468, 1.3981, 1.311, 1.2601, 1.2564, 1.1026, 1.0523, 1.0009, 0.8239, 0.7232, 0.5946, 0.5025, 0.4531, 0.3732, 0.3356, 0.2749, 0.2573, 0.2555, 0.2292, 0.209, 0.1735, 0.0312, 0.0485, -0.721, -0.4321, -0.6571, -0.7851, -1.3666, 2.1711, 2.1703, 2.1371, 2.1239, 2.1239, 1.8996, 1.8873, 1.8114, 1.7257, 1.6536, 1.335, 1.2158, 1.181, 1.0323, 1.0028, 0.9383, 0.912, 0.8978, 0.7649, 0.7441, 0.6542, 0.5849, 0.5277, 0.5123, 0.4226, 0.3698, 0.3261, 0.3158, 0.2495, 0.1601, 0.1554, 0.1312, 0.1314, -0.0168, 0.0953, 0.1421, -0.3847, -0.3644, -0.4638, 2.1212, 1.9525, 1.898, 1.832, 1.6596, 1.5114, 1.4987, 1.4545, 1.4436, 1.3971, 1.3956, 1.3323, 1.2496, 1.1531, 1.1087, 1.0791, 0.9354, 0.8238, 0.8068, 0.7992, 0.7794, 0.7238, 0.653, 0.6455, 0.6452, 0.6259, 0.5813, 0.4808, 0.409, 0.3359, 0.3358, 0.3227, 0.149, 0.0395, 0.1385, -0.0033, -0.5854, -0.2296, 0.2286, -0.3446, 0.0528, 2.8646, 2.8571, 2.8388, 2.8318, 2.8177, 2.8045, 2.7972, 2.6405, 2.6139, 2.3786, 2.3776, 2.1787, 2.0513, 1.9075, 1.8564, 1.8563, 1.6762, 1.6499, 1.6279, 1.6274, 1.0829, 1.0583, 0.9859, 0.8963, 0.7163, 0.6735, 0.6449, 0.4776, 0.3308, 0.3029, -0.2044, -0.5472, -0.8432, -0.7774, -1.0616, -1.6603]}, \"token.table\": {\"Topic\": [1, 4, 5, 7, 8, 8, 3, 6, 8, 1, 2, 3, 5, 8, 1, 2, 3, 8, 4, 1, 2, 3, 4, 5, 7, 8, 1, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 4, 6, 2, 4, 5, 7, 2, 3, 4, 5, 7, 2, 5, 2, 5, 6, 4, 5, 8, 2, 7, 2, 3, 5, 6, 2, 7, 1, 3, 4, 5, 6, 7, 8, 1, 4, 6, 3, 6, 7, 1, 2, 3, 7, 8, 1, 5, 3, 4, 7, 1, 3, 4, 5, 6, 8, 4, 1, 3, 4, 5, 6, 7, 8, 2, 7, 3, 4, 7, 1, 8, 2, 2, 2, 7, 8, 2, 7, 2, 1, 2, 3, 4, 5, 6, 7, 8, 3, 7, 8, 1, 4, 5, 6, 7, 8, 2, 7, 1, 6, 7, 2, 1, 2, 3, 6, 1, 4, 5, 8, 2, 3, 3, 8, 1, 5, 7, 8, 1, 2, 3, 4, 5, 7, 8, 2, 3, 4, 6, 7, 2, 4, 5, 2, 7, 1, 2, 5, 6, 7, 8, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 1, 3, 4, 6, 8, 2, 3, 4, 5, 7, 1, 2, 5, 7, 8, 5, 4, 5, 1, 3, 4, 5, 6, 8, 1, 5, 3, 5, 2, 7, 1, 2, 3, 4, 5, 7, 8, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 3, 2, 5, 1, 2, 7, 2, 7, 1, 3, 4, 5, 6, 7, 8, 1, 4, 6, 1, 3, 8, 1, 2, 3, 6, 8, 1, 2, 3, 4, 5, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 8, 3, 4, 7, 8, 1, 5, 6, 8, 4, 7, 3, 6, 7, 8, 4, 5, 6, 7, 3, 6, 7, 1, 7, 2, 5, 8, 8, 6, 8, 1, 6, 7, 1, 5, 6, 8, 1, 2, 3, 4, 5, 1, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 2, 4, 7, 3, 6, 8, 1, 6, 7, 1, 2, 3, 6, 2, 3, 4, 5, 6, 5, 6, 7, 1, 3, 4, 5, 6, 7, 1, 3, 5, 6, 1, 3, 4, 6, 1, 3, 3, 6, 1, 6, 8, 5, 8, 3, 8, 1, 3, 7, 8, 5, 1, 5, 6, 2, 5, 1, 3, 6, 4, 3, 4, 6, 7, 3, 4, 6, 7, 7, 8, 1, 3, 6, 6, 1, 3, 5, 7, 1, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 3, 6, 7, 1, 2, 4, 5, 6, 7], \"Freq\": [0.2821876300332242, 0.3292189017054283, 0.1410938150166121, 0.047031271672204035, 0.1410938150166121, 0.8628386198263601, 0.5304416522200691, 0.10608833044401382, 0.21217666088802764, 0.1734567703594474, 0.2601851555391711, 0.05781892345314913, 0.49146084935176765, 0.028909461726574565, 0.052264156001934625, 0.052264156001934625, 0.7839623400290194, 0.052264156001934625, 0.9535169339678594, 0.13161298991829393, 0.3948389697548818, 0.08043016050562407, 0.1974194848774409, 0.058494662185908416, 0.10236565882533973, 0.029247331092954208, 0.5062932327957433, 0.09205331505377151, 0.18410663010754302, 0.023013328763442878, 0.11506664381721439, 0.06903998629032863, 0.023013328763442878, 0.186920195255278, 0.02336502440690975, 0.6853740492693526, 0.0467300488138195, 0.0467300488138195, 0.0077883414689699166, 0.032815483644293084, 0.032815483644293084, 0.9188335420402064, 0.5373857979117168, 0.24426627177805307, 0.07327988153341593, 0.14655976306683186, 0.08171581071898344, 0.34320640501973043, 0.09805897286278013, 0.016343162143796688, 0.45760854002630724, 0.08456779398285146, 0.8456779398285145, 0.5445172846058621, 0.3267103707635173, 0.10890345692117243, 0.9197541084450339, 0.788573576199397, 0.1126533680284853, 0.7766685278792632, 0.17259300619539183, 0.7940080009443827, 0.04291935140239907, 0.10729837850599766, 0.021459675701199533, 0.7087899523785488, 0.2657962321419558, 0.46498308961905915, 0.02818079331024601, 0.17847835763155806, 0.02818079331024601, 0.10802637435594303, 0.19256875428668108, 0.004696798885041002, 0.04462284013240638, 0.7808997023171117, 0.15617994046342235, 0.04616737973779628, 0.27700427842677766, 0.6463433163291479, 0.12662574423462747, 0.025325148846925494, 0.3798772327038824, 0.12662574423462747, 0.3292269350100314, 0.5802621935289913, 0.3481573161173948, 0.491313480106596, 0.05459038667851066, 0.40942790008882995, 0.5153471296912434, 0.10571223173153713, 0.02642805793288428, 0.01321402896644214, 0.0660701448322107, 0.2642805793288428, 0.9433701897265303, 0.673641443965775, 0.029288758433294565, 0.04881459738882427, 0.11715503373317826, 0.009762919477764854, 0.11715503373317826, 0.009762919477764854, 0.4748376602681873, 0.3561282452011405, 0.3158487574482816, 0.06316975148965633, 0.5053580119172506, 0.12480044292016819, 0.7488026575210092, 0.9503111132532154, 0.951084115344489, 0.8176462953185792, 0.1721360621723325, 0.8955609895074489, 0.7843035445659425, 0.1845420104861041, 0.9505801592922217, 0.4044584030756876, 0.02543763541356526, 0.08648796040612187, 0.24165753642886995, 0.053419034368487044, 0.12464441352646977, 0.05596279790984357, 0.010175054165426103, 0.2771210634594245, 0.09237368781980816, 0.554242126918849, 0.2944190194500336, 0.06691341351137127, 0.38809779836595343, 0.1204441443204683, 0.013382682702274256, 0.10706146161819405, 0.6087196054061181, 0.33817755855895454, 0.04620276331767095, 0.9009538846945836, 0.023101381658835476, 0.8371170677171885, 0.2616336811634242, 0.3737624016620346, 0.07475248033240693, 0.2990099213296277, 0.8484056287650827, 0.05302535179781767, 0.7013119509533409, 0.2629919816075028, 0.5998050065273074, 0.2999025032636537, 0.12436702714310013, 0.870569190001701, 0.670173729179639, 0.07446374768662656, 0.07446374768662656, 0.07446374768662656, 0.02559464864171156, 0.7678394592513469, 0.00639866216042789, 0.08318260808556258, 0.01919598648128367, 0.08318260808556258, 0.01279732432085578, 0.7122996075290347, 0.030969548153436288, 0.07742387038359072, 0.030969548153436288, 0.1393629666904633, 0.573286729478488, 0.16379620842242515, 0.24569431263363772, 0.758181595256098, 0.1895453988140245, 0.45708547580970554, 0.05713568447621319, 0.17140705342863957, 0.11427136895242639, 0.05713568447621319, 0.05713568447621319, 0.4458412614443616, 0.4458412614443616, 0.013892870659573663, 0.1806073185744576, 0.09725009461701564, 0.027785741319147326, 0.5140362144042255, 0.12503583593616296, 0.013892870659573663, 0.027785741319147326, 0.9068607862757936, 0.2506556891245412, 0.1253278445622706, 0.37598353368681187, 0.2255901202120871, 0.025065568912454123, 0.046522997664014853, 0.37218398131211883, 0.11630749416003713, 0.023261498832007427, 0.4187069789761337, 0.40459523395579805, 0.08669897870481387, 0.40459523395579805, 0.043349489352406935, 0.02889965956827129, 0.9502450882920419, 0.8593661116980132, 0.09548512352200147, 0.16303081050282167, 0.008151540525141084, 0.04075770262570542, 0.7336386472626976, 0.008151540525141084, 0.04075770262570542, 0.6991456994565522, 0.23304856648551742, 0.8023427778424772, 0.10029284723030965, 0.6793101294037834, 0.295352230175558, 0.060433380570874606, 0.7453450270407869, 0.020144460190291535, 0.08057784076116614, 0.020144460190291535, 0.04028892038058307, 0.020144460190291535, 0.5543852423838652, 0.09239754039731086, 0.2771926211919326, 0.33411946958249433, 0.22533638646261248, 0.06216176178278965, 0.2874981482454021, 0.007770220222848706, 0.07770220222848706, 0.007770220222848706, 0.9690639704276864, 0.20051293971491257, 0.701795289002194, 0.36501736712211313, 0.15817419241958236, 0.46235533168800996, 0.7363521401475126, 0.21038632575643218, 0.40565037397666454, 0.03380419783138871, 0.18028905510073978, 0.005634032971898118, 0.23099535184782286, 0.11831469240986049, 0.016902098915694354, 0.04520995621081081, 0.5425194745297297, 0.36167964968648647, 0.7242477050339493, 0.06584070045763175, 0.16460175114407938, 0.07186482126705102, 0.28745928506820406, 0.4311889276023061, 0.17966205316762754, 0.03593241063352551, 0.21955284387915266, 0.2079974310434078, 0.1502203668646834, 0.27732990805787705, 0.13866495402893853, 0.022875862437870945, 0.7549034604497412, 0.09150344975148378, 0.09150344975148378, 0.07885811809519061, 0.11828717714278592, 0.453434179047346, 0.01478589714284824, 0.1527876038094318, 0.15771623619038122, 0.024643161904747066, 0.03991606828556649, 0.43907675114123146, 0.43907675114123146, 0.07983213657113299, 0.4279308871817362, 0.1711723548726945, 0.08558617743634725, 0.2567585323090417, 0.21571168059904053, 0.6471350417971216, 0.49634653325628075, 0.35453323804020054, 0.07090664760804011, 0.8761387518030519, 0.45431857093636424, 0.22715928546818212, 0.22715928546818212, 0.11357964273409106, 0.07803864361531936, 0.7023477925378743, 0.1560772872306387, 0.7622393587299875, 0.09527991984124844, 0.11046616405844886, 0.4050426015476458, 0.44186465623379545, 0.8753962572088783, 0.6750972264761205, 0.11251620441268674, 0.054331646300798855, 0.054331646300798855, 0.8421405176623823, 0.027977494380925352, 0.5035948988566563, 0.13988747190462675, 0.33572993257110423, 0.22386934933572494, 0.21208675200226573, 0.1296085706680513, 0.2945649333364802, 0.1413911680015105, 0.6879241752669012, 0.2293080584223004, 0.35183476471934966, 0.11502290385055661, 0.013532106335359602, 0.14885316968895562, 0.12855501018591622, 0.006766053167679801, 0.2232797545334334, 0.2676708842619878, 0.19119348875856274, 0.03823869775171255, 0.4461181404366464, 0.025492465167808367, 0.012746232583904183, 0.8429416706311372, 0.02107354176577843, 0.10536770882889215, 0.0718685702793802, 0.5749485622350416, 0.35934285139690103, 0.5458827330006897, 0.013996993153863838, 0.433906787769779, 0.04457604111951606, 0.6686406167927409, 0.08915208223903212, 0.13372812335854817, 0.024645878026711057, 0.3203964143472437, 0.29575053632053266, 0.07393763408013317, 0.27110465829382163, 0.6402923938193545, 0.09147034197419351, 0.18294068394838703, 0.19914732871795945, 0.2928637187028815, 0.0937163899849221, 0.14057458497738315, 0.2108618774660747, 0.07028729248869157, 0.03813440201005501, 0.49574722613071515, 0.3050752160804401, 0.19067201005027506, 0.15690093348813486, 0.13448651441840132, 0.40345954325520395, 0.29138744790653615, 0.22030683741266135, 0.7049818797205163, 0.02543181837627526, 0.9409772799221846, 0.5204321385153958, 0.41634571081231664, 0.9139460054456465, 0.19862069296397836, 0.6951724253739243, 0.37563390618306153, 0.5634508592745924, 0.2793195392765634, 0.38406436650527465, 0.24440459686699295, 0.10474482722871126, 0.9503575185207233, 0.11368049337183189, 0.6820829602309914, 0.11368049337183189, 0.7231535918439567, 0.12052559864065944, 0.5711495297916734, 0.2855747648958367, 0.07139369122395918, 0.9023096027526554, 0.15640166910106773, 0.3910041727526693, 0.07820083455053387, 0.3910041727526693, 0.0602666663102724, 0.0602666663102724, 0.1205333326205448, 0.7231999957232689, 0.09782260800232316, 0.8804034720209085, 0.22912731080514562, 0.057281827701286404, 0.6873819324154369, 0.9669125289183309, 0.632063061054452, 0.03326647689760273, 0.09979943069280821, 0.23286533828321915, 0.046203089893861335, 0.900960252930296, 0.023101544946930667, 0.18239171114703515, 0.006079723704901172, 0.49853734380189607, 0.03647834222940703, 0.07295668445881406, 0.07295668445881406, 0.10335530298331992, 0.024318894819604687, 0.11249816036881381, 0.5624908018440691, 0.22499632073762763, 0.2744027121431725, 0.034300339017896565, 0.24010237312527596, 0.06860067803579313, 0.2744027121431725, 0.1029010170536897], \"Term\": [\"accessory\", \"accessory\", \"accessory\", \"accessory\", \"accessory\", \"ankle\", \"architecture\", \"architecture\", \"architecture\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"art\", \"art\", \"art\", \"art\", \"bag\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"beige\", \"beige\", \"beige\", \"beige\", \"beige\", \"beige\", \"beige\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"blazer\", \"blazer\", \"blazer\", \"blond\", \"blond\", \"blond\", \"blond\", \"blue\", \"blue\", \"blue\", \"blue\", \"blue\", \"body\", \"body\", \"brown\", \"brown\", \"brown\", \"canidae\", \"chair\", \"chair\", \"cheek\", \"cheek\", \"child\", \"child\", \"child\", \"child\", \"chin\", \"chin\", \"clothe\", \"clothe\", \"clothe\", \"clothe\", \"clothe\", \"clothe\", \"clothe\", \"coat\", \"coat\", \"coat\", \"collar\", \"collar\", \"collar\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"costume\", \"costume\", \"denim\", \"denim\", \"denim\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"dog\", \"dress\", \"dress\", \"dress\", \"dress\", \"dress\", \"dress\", \"dress\", \"ear\", \"ear\", \"electric\", \"electric\", \"electric\", \"equipment\", \"equipment\", \"expression\", \"eye\", \"eyebrow\", \"eyebrow\", \"eyewear\", \"face\", \"face\", \"facial\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"font\", \"font\", \"font\", \"footwear\", \"footwear\", \"footwear\", \"footwear\", \"footwear\", \"footwear\", \"forehead\", \"forehead\", \"formal\", \"formal\", \"formal\", \"friendship\", \"fun\", \"fun\", \"fun\", \"fun\", \"fur\", \"fur\", \"furniture\", \"furniture\", \"gesture\", \"gesture\", \"glass\", \"glass\", \"green\", \"green\", \"green\", \"green\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hairstyle\", \"hairstyle\", \"hairstyle\", \"hairstyle\", \"hairstyle\", \"hand\", \"hand\", \"hand\", \"head\", \"head\", \"headgear\", \"headgear\", \"headgear\", \"headgear\", \"headgear\", \"headgear\", \"high\", \"high\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"illustration\", \"jacket\", \"jacket\", \"jacket\", \"jacket\", \"jacket\", \"jeans\", \"jeans\", \"jeans\", \"jeans\", \"jeans\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"knee\", \"leather\", \"leather\", \"leg\", \"leg\", \"leg\", \"leg\", \"leg\", \"leg\", \"leisure\", \"leisure\", \"light\", \"light\", \"lip\", \"lip\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"magenta\", \"magenta\", \"magenta\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"monochrome\", \"muscle\", \"muscle\", \"neck\", \"neck\", \"neck\", \"nose\", \"nose\", \"outerwear\", \"outerwear\", \"outerwear\", \"outerwear\", \"outerwear\", \"outerwear\", \"outerwear\", \"overcoat\", \"overcoat\", \"overcoat\", \"pattern\", \"pattern\", \"pattern\", \"people\", \"people\", \"people\", \"people\", \"people\", \"photo\", \"photo\", \"photo\", \"photo\", \"photo\", \"photograph\", \"photograph\", \"photograph\", \"photograph\", \"photography\", \"photography\", \"photography\", \"photography\", \"photography\", \"photography\", \"photography\", \"pink\", \"pink\", \"pink\", \"pink\", \"plant\", \"plant\", \"plant\", \"plant\", \"pocket\", \"pocket\", \"portrait\", \"portrait\", \"portrait\", \"product\", \"purple\", \"purple\", \"purple\", \"purple\", \"red\", \"red\", \"red\", \"robe\", \"robe\", \"room\", \"room\", \"room\", \"sandal\", \"sea\", \"sea\", \"shirt\", \"shirt\", \"shirt\", \"shoe\", \"shoe\", \"shoe\", \"shoe\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"short\", \"short\", \"shoulder\", \"shoulder\", \"shoulder\", \"shoulder\", \"shoulder\", \"shoulder\", \"shoulder\", \"sit\", \"sit\", \"sit\", \"sit\", \"sit\", \"sit\", \"skin\", \"skin\", \"skin\", \"sky\", \"sky\", \"sky\", \"sleeve\", \"sleeve\", \"sleeve\", \"smile\", \"smile\", \"smile\", \"smile\", \"snapshot\", \"snapshot\", \"snapshot\", \"snapshot\", \"snapshot\", \"sportswear\", \"sportswear\", \"sportswear\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stock\", \"stock\", \"stock\", \"stock\", \"street\", \"street\", \"street\", \"street\", \"style\", \"style\", \"suit\", \"suit\", \"summer\", \"summer\", \"sunglasses\", \"table\", \"table\", \"text\", \"text\", \"textile\", \"textile\", \"textile\", \"textile\", \"thigh\", \"tights\", \"tights\", \"tights\", \"toddler\", \"toddler\", \"tree\", \"tree\", \"tree\", \"trench\", \"trousers\", \"trousers\", \"trousers\", \"trousers\", \"turquoise\", \"turquoise\", \"turquoise\", \"turquoise\", \"uniform\", \"uniform\", \"vacation\", \"vacation\", \"vacation\", \"vehicle\", \"waist\", \"waist\", \"waist\", \"waist\", \"wear\", \"wear\", \"wear\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"worker\", \"worker\", \"worker\", \"yellow\", \"yellow\", \"yellow\", \"yellow\", \"yellow\", \"yellow\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 1, 2, 6, 3, 8, 5, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1001406974487890006077534520\", ldavis_el1001406974487890006077534520_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1001406974487890006077534520\", ldavis_el1001406974487890006077534520_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1001406974487890006077534520\", ldavis_el1001406974487890006077534520_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "6     -0.014304  0.105583       1        1  20.385327\n",
              "0      0.230220 -0.203652       2        1  16.140493\n",
              "1     -0.054143  0.043103       3        1  14.097020\n",
              "5      0.080622  0.114403       4        1  12.069143\n",
              "2     -0.094700 -0.123564       5        1  11.090296\n",
              "7     -0.076704  0.185774       6        1  10.825633\n",
              "4      0.166595  0.037487       7        1  10.197071\n",
              "3     -0.237587 -0.159135       8        1   5.195017, topic_info=           Term        Freq       Total Category  logprob  loglift\n",
              "84          leg  122.000000  122.000000  Default  30.0000  30.0000\n",
              "24         hair  156.000000  156.000000  Default  29.0000  29.0000\n",
              "37        black  128.000000  128.000000  Default  28.0000  28.0000\n",
              "8   photography  202.000000  202.000000  Default  27.0000  27.0000\n",
              "0        clothe  212.000000  212.000000  Default  26.0000  26.0000\n",
              "..          ...         ...         ...      ...      ...      ...\n",
              "18       beauty    4.110895  136.764616   Topic8  -4.1876  -0.5472\n",
              "8   photography    4.535900  202.896041   Topic8  -4.0892  -0.8432\n",
              "42        white    3.927067  164.481159   Topic8  -4.2334  -0.7774\n",
              "7     outerwear    3.189476  177.492749   Topic8  -4.4414  -1.0616\n",
              "3       fashion    3.881893  393.118300   Topic8  -4.2449  -1.6603\n",
              "\n",
              "[334 rows x 6 columns], token_table=      Topic      Freq       Term\n",
              "term                            \n",
              "47        1  0.282188  accessory\n",
              "47        4  0.329219  accessory\n",
              "47        5  0.141094  accessory\n",
              "47        7  0.047031  accessory\n",
              "47        8  0.141094  accessory\n",
              "...     ...       ...        ...\n",
              "109       2  0.034300     yellow\n",
              "109       4  0.240102     yellow\n",
              "109       5  0.068601     yellow\n",
              "109       6  0.274403     yellow\n",
              "109       7  0.102901     yellow\n",
              "\n",
              "[435 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 1, 2, 6, 3, 8, 5, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}