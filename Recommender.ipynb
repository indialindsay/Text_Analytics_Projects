{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\india\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\india\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "''' Installing neccesary libraries'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk #for natural language processing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords #to remove stopwords\n",
    "stop = set(stopwords.words('english')) #remove common english stopwords\n",
    "stop.remove('not') #can convey different sentiment, we want to keep not\n",
    "import re #importing regular expression to clean reviews\n",
    "\n",
    "\n",
    "import string\n",
    "from scipy import spatial #calculating bag-of-words cosine similarity\n",
    "\n",
    "import spacy #for calculating word vector cosine similarity\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer #using Vader tool for sentiment analysis \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset Containing WebScraped Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_reviews = pd.read_csv('REALbeer_reviews.csv') \n",
    "beer_reviews['product_review'] = beer_reviews['product_review'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Recommender:\n",
    "\n",
    "    def __init__(self,attributes): #must be 3 attributes\n",
    "        self.attr = attributes\n",
    "\n",
    "    def CosSim(self, review):  # calculates cosine similary\n",
    "        reviews = review\n",
    "        feature_vector = [1.0, 1.0, 1.0]\n",
    "        cosine_sim = []  # empty list to store cos score\n",
    "        for rev in reviews:\n",
    "            review_vector = self.generate_bow(rev)  # returns array containing number of times each attr occurs in rev\n",
    "            cosine_similarity = 1 - spatial.distance.cosine(feature_vector, review_vector)\n",
    "            # calculates cosine distance of each review and our list of attributes\n",
    "            cosine_sim.append(cosine_similarity)  # adds cosine score for each review to our list\n",
    "\n",
    "        # cosine sim will return nan if attributes were not present in the review\n",
    "        # we will convert these to zeros and transform it to a pandas series\n",
    "        cosine_sim = pd.Series(cosine_sim).fillna(0)\n",
    "        return cosine_sim\n",
    "\n",
    "    def generate_bow(self, review):\n",
    "        ''' returns an array with the number of times each attribute occurs in each review '''\n",
    "        words = self.word_extraction(review)  # returns cleaned list of words in review\n",
    "        bag_vector = np.zeros(len(self.attr))  # creates a vector of zeros for the number of attributes\n",
    "\n",
    "        for w in words:  # for each word in the review\n",
    "            for i, word in enumerate(self.attr):  # for each attribute\n",
    "                if word == w:  # if the word is an attribute\n",
    "                    bag_vector[i] = 1  # increment index of attribute\n",
    "        return np.array(bag_vector)\n",
    "\n",
    "    def word_extraction(self, sentence):\n",
    "        ''' returns list of words in review after removing specific stop words, punctuation, and digits'''\n",
    "        # ignore = ['a', \"the\", \"is\"] #remove these words\n",
    "        words = re.sub(\"[^\\w]\", \" \", sentence).split()  # remove punctuation and digits\n",
    "        cleaned_text = [w.lower() for w in words if w not in stop]\n",
    "        return cleaned_text\n",
    "    \n",
    "        \n",
    "    def word_window(self,string,n,keyword):\n",
    "    \n",
    "        '''Searches for keyword in text and returns n words on either side of it as a tuple'''\n",
    "    \n",
    "    \n",
    "        '''splitting words seperated by spaces, want to contain all capitalization and \n",
    "        punctuation as it contains sentiment, also removing all stopwords'''\n",
    "\n",
    "        string_tokens = string.split() \n",
    "        string_no_sw = [word for word in string_tokens if not word in stop] \n",
    "    \n",
    "        #empty list to store words before and after keyword\n",
    "        window = ''\n",
    "    \n",
    "        #identifying if keyword in string and then grabbing 3 words before and 3 words after\n",
    "        for i in range(len(string_no_sw)):\n",
    "            word = string_no_sw[i]\n",
    "            if word == keyword:\n",
    "            \n",
    "                #words that appear before keyword\n",
    "                while (i-n) >= 0 and n >= 1:\n",
    "                    window += string_no_sw[i-n] + ' '\n",
    "                    n = n - 1\n",
    "            \n",
    "                #words that appear after keyword\n",
    "                while (i+n) <= (len(string_no_sw)-1) and n <= 3:\n",
    "                    window += string_no_sw[i+n] + ' '\n",
    "                    n = n + 1\n",
    "                \n",
    "        return window\n",
    "\n",
    "    def sentiment_score(self,review_column,attribute):\n",
    "\n",
    "        '''  this function finds the sentiment for a window of words surrounding each attribute in each review'''\n",
    "        \n",
    "       \n",
    "        analyzer = SentimentIntensityAnalyzer() #creating sentiment-intensity-analyzer object\n",
    "        review_index = 0 #keeps track of index of review\n",
    "        attribute_score = []\n",
    "        \n",
    "        for rev in review_column:\n",
    "        \n",
    "            \n",
    "            has_attributes = False #variable to check if review contains attributes\n",
    "    \n",
    "            for word in rev.split(): #for each word in the review\n",
    "            \n",
    "                word2 = word.lower() #only grab lower case to identify presence of attribute\n",
    "     \n",
    "           \n",
    "                if word2 == attribute: #if word is an attribute\n",
    "                    has_attributes = True #we know this review contains an attribute \n",
    "                    a = word2\n",
    "                    window = self.word_window(rev,3,word) #grabbing window of 3 surrounding words in each direction \n",
    "                    score = analyzer.polarity_scores(window) #grab the sentiment score of this window of words\n",
    "                    score = score['compound'] #grab the total compound score\n",
    "                    #this grabs multiple mentions of same attribute in one review\n",
    "                    attribute_score.append(score)\n",
    "                    \n",
    "            if has_attributes == False: # if rev contained no attributes.. update as np.nan for all attr to keep review in df \n",
    "                attribute_score.append(np.nan)\n",
    "            review_index += 1 #increments review index     \n",
    "        \n",
    "        attribute_score = pd.Series(attribute_score)\n",
    "        return attribute_score\n",
    "    \n",
    "    def eval_scores(self,df,sim_score_col):\n",
    "        attr1 =str(self.attr[0])\n",
    "        attr2 = str(self.attr[1])\n",
    "        attr3 = str(self.attr[2])\n",
    "    \n",
    "        '''evaluation scores for regular cosine similarity'''\n",
    "        df[attr1 + ' cosine eval score'] = (df[sim_score_col] + df[attr1 + ' sentiment score']) / 2\n",
    "        df[attr2 + ' cosine eval score'] = (df[sim_score_col] + df[attr2 + ' sentiment score']) / 2\n",
    "        df[attr3 + ' cosine eval score'] = (df[sim_score_col] + df[attr3 + ' sentiment score']) / 2\n",
    "    \n",
    "        df['Overall_eval_score'] = (df[sim_score_col] + df[attr1 + ' cosine eval score'] + \\\n",
    "                                        df[attr2 + ' cosine eval score'] + df[attr3 + ' cosine eval score']) / 4\n",
    "    \n",
    "        df = df.fillna(0)\n",
    "        df = df.sort_values(by='Overall_eval_score', ascending=False)\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "    def Run(self,review_col,df,prod_name_col): \n",
    "        df['Similarity_Score'] = self.CosSim(review_col) #returns column w similarity score\n",
    "        for i in range(len(self.attr)):\n",
    "            attr =str(self.attr[i])\n",
    "            df[attr + ' sentiment score'] = self.sentiment_score(review_col,attr)\n",
    "        #grouping by mean scores\n",
    "        df = df.groupby([prod_name_col])[[self.attr[0]+ ' sentiment score',self.attr[1]+ ' sentiment score',self.attr[2]+ ' sentiment score','Similarity_Score']].mean()\n",
    "       \n",
    "        #calculating overal evaluation scores\n",
    "        df = self.eval_scores(df,'Similarity_Score')\n",
    "        df = df.sort_values(by='Overall_eval_score', ascending=False)\n",
    "        prod1 = df.index[0]\n",
    "        prod2 = df.index[1]\n",
    "        prod3 = df.index[2]\n",
    "        rec = \"Based upon your preferences, we recommend the following 3 beers: \" + prod1 + ', ' + prod2 + ', and ' + prod3 + '!'\n",
    "        print(rec)\n",
    "        return df\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the recommendations based upon input attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based upon your preferences, we recommend the following 3 beers: Emerald Grouper, 3rd Anniversary Imperial IPA, and Swish!\n"
     ]
    }
   ],
   "source": [
    "a = Recommender(['fruit','citrus','smooth'])\n",
    "new = a.Run(beer_reviews['product_review'], beer_reviews,'product_name') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their overall scores can be observed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit sentiment score</th>\n",
       "      <th>citrus sentiment score</th>\n",
       "      <th>smooth sentiment score</th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>fruit cosine eval score</th>\n",
       "      <th>citrus cosine eval score</th>\n",
       "      <th>smooth cosine eval score</th>\n",
       "      <th>Overall_eval_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Emerald Grouper</th>\n",
       "      <td>0.551067</td>\n",
       "      <td>0.61705</td>\n",
       "      <td>0.384533</td>\n",
       "      <td>0.418486</td>\n",
       "      <td>0.484776</td>\n",
       "      <td>0.517768</td>\n",
       "      <td>0.401509</td>\n",
       "      <td>0.455635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd Anniversary Imperial IPA</th>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.51060</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.401580</td>\n",
       "      <td>0.568340</td>\n",
       "      <td>0.456090</td>\n",
       "      <td>0.280340</td>\n",
       "      <td>0.426587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swish</th>\n",
       "      <td>0.188720</td>\n",
       "      <td>0.41808</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.365542</td>\n",
       "      <td>0.277131</td>\n",
       "      <td>0.391811</td>\n",
       "      <td>0.546221</td>\n",
       "      <td>0.395176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fruit sentiment score  citrus sentiment score  \\\n",
       "product_name                                                                  \n",
       "Emerald Grouper                            0.551067                 0.61705   \n",
       "3rd Anniversary Imperial IPA               0.735100                 0.51060   \n",
       "Swish                                      0.188720                 0.41808   \n",
       "\n",
       "                              smooth sentiment score  Similarity_Score  \\\n",
       "product_name                                                             \n",
       "Emerald Grouper                             0.384533          0.418486   \n",
       "3rd Anniversary Imperial IPA                0.159100          0.401580   \n",
       "Swish                                       0.726900          0.365542   \n",
       "\n",
       "                              fruit cosine eval score  \\\n",
       "product_name                                            \n",
       "Emerald Grouper                              0.484776   \n",
       "3rd Anniversary Imperial IPA                 0.568340   \n",
       "Swish                                        0.277131   \n",
       "\n",
       "                              citrus cosine eval score  \\\n",
       "product_name                                             \n",
       "Emerald Grouper                               0.517768   \n",
       "3rd Anniversary Imperial IPA                  0.456090   \n",
       "Swish                                         0.391811   \n",
       "\n",
       "                              smooth cosine eval score  Overall_eval_score  \n",
       "product_name                                                                \n",
       "Emerald Grouper                               0.401509            0.455635  \n",
       "3rd Anniversary Imperial IPA                  0.280340            0.426587  \n",
       "Swish                                         0.546221            0.395176  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
